{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## The intro\n",
    "\n",
    "Anyway. I'm sure you guys have a lot to do this week, so we'll try to keep it relatively light (although there should be enough optional exercises to keep you all busy).\n",
    "\n",
    "[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/6b4EQk96SfQ/0.jpg)](https://www.youtube.com/watch?v=6b4EQk96SfQ)\n",
    "\n",
    "Remember that last week you worked classifing data using *KNN*'s. We are going to continue working with machine learning, this time looking at *decision trees* and see how new information can influence the performance of our model in predicting which type of crime happened.\n",
    "\n",
    "Specifically, crimes can have many causes, so we can combine datasouces to better understand what makes a criminal commit a crime. Are there specific factors which trigger that individual to act? Since criminals are notoriously shy about sharing information, we must try to find this out in a different way. Lucky for us, we can do this with data! \n",
    "\n",
    "*We are going to use weather data* from San Franciso to try to relate different crimes with meteorological conditions!\n",
    "\n",
    "* We'll start with a relatively simple exercise focusing adding weather data to the decision tree from last week (Part 1, 2, and 3).\n",
    "* Then we'll prepare a bit for next week, when we get into the topic of explanatory data visualization with some lectures and reading (Part 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Decision Tree Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we turn to decision trees. This is a fantastically useful supervised machine-learning method, that we use all the time in research. To get started on the decision trees, we'll use some fantastic *visual* introduction. \n",
    "\n",
    "\n",
    "*Decision Trees Reading 1*: The visual introduction to decision trees on this webpage is AMAZING. Take a look to get an intuitive feel for how trees work. Do not miss this one, it's a treat! http://www.r2d3.us/visual-intro-to-machine-learning-part-1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Decision Trees Reading 2*: the second part of the visual introduction is about the topic of model selection, and bias/variance tradeoffs that we looked into earlier during this lesson. But once again, here those topics are visualized in a fantastic and inspiring way, that will make it stick in your brain better. So check it out http://www.r2d3.us/visual-intro-to-machine-learning-part-2/\n",
    "\n",
    "*Decision Trees Reading 3*: Finally, you can also read about decision trees in DSFS, chapter 17. **You can get it on DTU Learn**\n",
    "\n",
    "And our little session on decision trees wouldn't be complete without hearing from Ole about these things. \n",
    "\n",
    "[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/LAA_CnkAEx8/0.jpg)](https://www.youtube.com/watch?v=LAA_CnkAEx8)\n",
    "\n",
    "\n",
    "*Decision tree \"reading\" 4*: And of course the best way to learn how to get this stuff rolling in practice, is to work through a tutorial or two. We recommend the ones below:\n",
    "  * https://jakevdp.github.io/PythonDataScienceHandbook/05.08-random-forests.html\n",
    "  * https://towardsdatascience.com/random-forest-in-python-24d0893d51c0 (this one also has good considerations regarding the one-hot encodings)\n",
    "  \n",
    "(But there are many other good ones out there.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ole explains decision trees\n",
    "# YouTubeVideo(\"LAA_CnkAEx8\",width=600, height=338)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Exercises: Just a few questions to make sure you've read the text (DSFS chapter 17) and/or watched the video.\n",
    "> \n",
    "> * There are two main kinds of decision trees depending on the type of output (numeric vs. categorical). What are they?\n",
    "    Classification trees and regression trees.\n",
    "> * Explain in your own words: Why is entropy useful when deciding where to split the data?\n",
    "    * Because when the split is close to 0 or 1 then the entropy gives a low value while when it is arround 0.5 meaning it splits the data in half it is a high value indicating a good split.\n",
    "> * Why are trees prone to overfitting? \n",
    "    * Because the model is very simple and you only stop training when you have made all splits pure. This can be adjusted by setting a minimum splitting boundry.\n",
    "    \n",
    "> * Explain (in your own words) how random forests help prevent overfitting.\n",
    "    * Random forrest introduces randomness and therefore variance moving decision trees more towards the middle where bias/variance tradoff is minimized. This is also known as regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Decision Tree Baseline\n",
    "\n",
    "\n",
    "> *Exercise*: Decision trees and real-world crime data\n",
    "> \n",
    "> The idea for today is to pick two crime-types that have *different geographical patterns* and *different temporal patterns*. We can then use various variables of the real crime data as categories to build a decision tree. I'm thinking we can use\n",
    "> * `DayOfWeek` (`Sunday`, ..., `Saturday`). (Note: Will need to be encodede as integer in `sklearn`)\n",
    "> * `PD District` (`TENDERLOIN`, etc). (Note: Will need to be encodede as integer in `sklearn`)\n",
    "> \n",
    "> And we can extract a few more from the `Time` and `Date` variables\n",
    "> * Hour of the day (1-24)\n",
    "> * Month of the year (1-12)\n",
    "> \n",
    "> So your job is to **select two crime categories** that (based on your analyses from the past three weeks) have different spatio-temporal patterns. Since we will use weather data to disitinguish later, let's try to think of crime categories that our intuition tells us might be strongly influenced by the weather conditions (type 1). And also think of other categories where we **don't** expect weather to play a role (type 2). We suggest:\n",
    "\n",
    "* `BURGLARY or VEHICLE THEFT` for type 1. \n",
    "* `FORGERY/COUNTERFEITIN or FRAUD` for type 2. \n",
    "\n",
    "But you are free to choose other ones, if you like ðŸ¤“\n",
    "\n",
    "Now we are going to to build is a decision tree (or, even better, a [Random Forest](https://jakevdp.github.io/PythonDataScienceHandbook/05.08-random-forests.html), here is [another tutorial for Random Forests](https://towardsdatascience.com/random-forest-in-python-24d0893d51c0)) classifier that takes as input the four labels (Hour-of-the-day, Day-of-the-week, Month-of-the-year, and PD-District) of a crime (from one of the two categories) and then tries to predict which category that crime is from.\n",
    ">\n",
    "> Some notes/hints\n",
    "> * Remember to create a balanced dataset, that is, **grab an equal number of examples** from each of the two crime categories. Pick categories with lots of training data. It's probably nice to have something like 10000+ examples of each category to train on. \n",
    "> * Also, I recommend you grab your training data at `random` from the set of all examples, since we want crimes to be distributed equally over time.\n",
    "> * A good option is the  `DecisionTreeClassifier`.\n",
    "> * We recommed you build a separate Pandas `Dataframe` with it, so the process of adding the weather data will be as smooth as possible later on. The same goes for your testing data.\n",
    "> * Create a function to evaluate the precision of your classifier. Make sure your test data is not used for training. (Since you have created a balanced dataset, the baseline performance (random guess) is 50%. How good can your classifier get?)\n",
    "> * (Optional, although this one might improve performance). Does one hot encoding affect your results? Why/Why not?  \n",
    "> * (Optional) Are your results tied to the specific training data you used? Are you overfitting? Try performing [cross-validation](https://towardsdatascience.com/cross-validation-in-machine-learning-72924a69872f) to answer this question.\n",
    "> * (Optional) If you find yourself with extra time, come back to this exercise and tweak the variables you use to see if you can improve the accuracy of the tree. Try for example adding Year, Month or other variables you think may be relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(r\"C:\\Users\\andri\\Documents\\Andri Geir\\DTU\\Social Data\\Police_Department_Incident_Reports__Historical_2003_to_May_2018.csv\")\n",
    "\n",
    "df= df[(pd.to_datetime(df['Date']) >= '01/01/2003')] \n",
    "df = df[(pd.to_datetime(df['Date']) <= '31/12/2017')] \n",
    "df['Year'] = pd.DatetimeIndex(df['Date']).year\n",
    "df['Month'] = pd.DatetimeIndex(df['Date']).month\n",
    "df['Day'] = pd.DatetimeIndex(df['Date']).day\n",
    "df['Hour'] = [int(time[0:2]) for time in (df['Time'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n",
      "40000\n",
      "80000\n"
     ]
    }
   ],
   "source": [
    "df_filtered1 = df[df[\"Category\"]==(\"VEHICLE THEFT\")].sample(40000)\n",
    "df_filtered2 = df[df[\"Category\"]==(\"FRAUD\")].sample(40000)\n",
    "print(len(df_filtered1))\n",
    "print(len(df_filtered2))\n",
    "df_balanced = pd.concat([df_filtered1,df_filtered2]).sample(frac=1).reset_index()\n",
    "print(len(df_balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>PdId</th>\n",
       "      <th>IncidntNum</th>\n",
       "      <th>Incident Code</th>\n",
       "      <th>Category</th>\n",
       "      <th>Descript</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>...</th>\n",
       "      <th>Areas of Vulnerability, 2016 2 2</th>\n",
       "      <th>Central Market/Tenderloin Boundary 2 2</th>\n",
       "      <th>Central Market/Tenderloin Boundary Polygon - Updated 2 2</th>\n",
       "      <th>HSOC Zones as of 2018-06-05 2 2</th>\n",
       "      <th>OWED Public Spaces 2 2</th>\n",
       "      <th>Neighborhoods 2</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1187079</td>\n",
       "      <td>15108197707021</td>\n",
       "      <td>151081977</td>\n",
       "      <td>7021</td>\n",
       "      <td>VEHICLE THEFT</td>\n",
       "      <td>STOLEN AUTOMOBILE</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>12/15/2015</td>\n",
       "      <td>10:45</td>\n",
       "      <td>RICHMOND</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1103969</td>\n",
       "      <td>13102687407021</td>\n",
       "      <td>131026874</td>\n",
       "      <td>7021</td>\n",
       "      <td>VEHICLE THEFT</td>\n",
       "      <td>STOLEN AUTOMOBILE</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>12/04/2013</td>\n",
       "      <td>16:00</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>752762</td>\n",
       "      <td>11006813407021</td>\n",
       "      <td>110068134</td>\n",
       "      <td>7021</td>\n",
       "      <td>VEHICLE THEFT</td>\n",
       "      <td>STOLEN AUTOMOBILE</td>\n",
       "      <td>Friday</td>\n",
       "      <td>01/21/2011</td>\n",
       "      <td>17:30</td>\n",
       "      <td>PARK</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1873745</td>\n",
       "      <td>6091038609320</td>\n",
       "      <td>60910386</td>\n",
       "      <td>9320</td>\n",
       "      <td>FRAUD</td>\n",
       "      <td>CREDIT CARD, THEFT BY USE OF</td>\n",
       "      <td>Friday</td>\n",
       "      <td>08/25/2006</td>\n",
       "      <td>20:45</td>\n",
       "      <td>SOUTHERN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.0</td>\n",
       "      <td>2006</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1089519</td>\n",
       "      <td>5106614007025</td>\n",
       "      <td>51066140</td>\n",
       "      <td>7025</td>\n",
       "      <td>VEHICLE THEFT</td>\n",
       "      <td>STOLEN TRUCK</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>09/20/2005</td>\n",
       "      <td>10:30</td>\n",
       "      <td>TARAVAL</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2005</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>104966</td>\n",
       "      <td>12037731707021</td>\n",
       "      <td>120377317</td>\n",
       "      <td>7021</td>\n",
       "      <td>VEHICLE THEFT</td>\n",
       "      <td>STOLEN AUTOMOBILE</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>05/12/2012</td>\n",
       "      <td>00:01</td>\n",
       "      <td>SOUTHERN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>1911726</td>\n",
       "      <td>12014221707021</td>\n",
       "      <td>120142217</td>\n",
       "      <td>7021</td>\n",
       "      <td>VEHICLE THEFT</td>\n",
       "      <td>STOLEN AUTOMOBILE</td>\n",
       "      <td>Monday</td>\n",
       "      <td>02/20/2012</td>\n",
       "      <td>09:15</td>\n",
       "      <td>INGLESIDE</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>1860148</td>\n",
       "      <td>13024151409320</td>\n",
       "      <td>130241514</td>\n",
       "      <td>9320</td>\n",
       "      <td>FRAUD</td>\n",
       "      <td>CREDIT CARD, THEFT BY USE OF</td>\n",
       "      <td>Monday</td>\n",
       "      <td>03/18/2013</td>\n",
       "      <td>00:01</td>\n",
       "      <td>PARK</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>1730407</td>\n",
       "      <td>4084563407025</td>\n",
       "      <td>40845634</td>\n",
       "      <td>7025</td>\n",
       "      <td>VEHICLE THEFT</td>\n",
       "      <td>STOLEN TRUCK</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>07/24/2004</td>\n",
       "      <td>23:30</td>\n",
       "      <td>SOUTHERN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2004</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>1532442</td>\n",
       "      <td>14028092227010</td>\n",
       "      <td>140280922</td>\n",
       "      <td>27010</td>\n",
       "      <td>FRAUD</td>\n",
       "      <td>DEFRAUDING AN INNKEEPER</td>\n",
       "      <td>Friday</td>\n",
       "      <td>04/04/2014</td>\n",
       "      <td>17:15</td>\n",
       "      <td>CENTRAL</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index            PdId  IncidntNum  Incident Code       Category  \\\n",
       "0      1187079  15108197707021   151081977           7021  VEHICLE THEFT   \n",
       "1      1103969  13102687407021   131026874           7021  VEHICLE THEFT   \n",
       "2       752762  11006813407021   110068134           7021  VEHICLE THEFT   \n",
       "3      1873745   6091038609320    60910386           9320          FRAUD   \n",
       "4      1089519   5106614007025    51066140           7025  VEHICLE THEFT   \n",
       "...        ...             ...         ...            ...            ...   \n",
       "79995   104966  12037731707021   120377317           7021  VEHICLE THEFT   \n",
       "79996  1911726  12014221707021   120142217           7021  VEHICLE THEFT   \n",
       "79997  1860148  13024151409320   130241514           9320          FRAUD   \n",
       "79998  1730407   4084563407025    40845634           7025  VEHICLE THEFT   \n",
       "79999  1532442  14028092227010   140280922          27010          FRAUD   \n",
       "\n",
       "                           Descript  DayOfWeek        Date   Time PdDistrict  \\\n",
       "0                 STOLEN AUTOMOBILE    Tuesday  12/15/2015  10:45   RICHMOND   \n",
       "1                 STOLEN AUTOMOBILE  Wednesday  12/04/2013  16:00   NORTHERN   \n",
       "2                 STOLEN AUTOMOBILE     Friday  01/21/2011  17:30       PARK   \n",
       "3      CREDIT CARD, THEFT BY USE OF     Friday  08/25/2006  20:45   SOUTHERN   \n",
       "4                      STOLEN TRUCK    Tuesday  09/20/2005  10:30    TARAVAL   \n",
       "...                             ...        ...         ...    ...        ...   \n",
       "79995             STOLEN AUTOMOBILE   Saturday  05/12/2012  00:01   SOUTHERN   \n",
       "79996             STOLEN AUTOMOBILE     Monday  02/20/2012  09:15  INGLESIDE   \n",
       "79997  CREDIT CARD, THEFT BY USE OF     Monday  03/18/2013  00:01       PARK   \n",
       "79998                  STOLEN TRUCK   Saturday  07/24/2004  23:30   SOUTHERN   \n",
       "79999       DEFRAUDING AN INNKEEPER     Friday  04/04/2014  17:15    CENTRAL   \n",
       "\n",
       "       ... Areas of Vulnerability, 2016 2 2  \\\n",
       "0      ...                              1.0   \n",
       "1      ...                              1.0   \n",
       "2      ...                              1.0   \n",
       "3      ...                              1.0   \n",
       "4      ...                              1.0   \n",
       "...    ...                              ...   \n",
       "79995  ...                              1.0   \n",
       "79996  ...                              1.0   \n",
       "79997  ...                              1.0   \n",
       "79998  ...                              2.0   \n",
       "79999  ...                              2.0   \n",
       "\n",
       "      Central Market/Tenderloin Boundary 2 2  \\\n",
       "0                                        NaN   \n",
       "1                                        NaN   \n",
       "2                                        NaN   \n",
       "3                                        NaN   \n",
       "4                                        NaN   \n",
       "...                                      ...   \n",
       "79995                                    NaN   \n",
       "79996                                    NaN   \n",
       "79997                                    NaN   \n",
       "79998                                    1.0   \n",
       "79999                                    NaN   \n",
       "\n",
       "       Central Market/Tenderloin Boundary Polygon - Updated 2 2  \\\n",
       "0                                                    NaN          \n",
       "1                                                    NaN          \n",
       "2                                                    NaN          \n",
       "3                                                    NaN          \n",
       "4                                                    NaN          \n",
       "...                                                  ...          \n",
       "79995                                                NaN          \n",
       "79996                                                NaN          \n",
       "79997                                                NaN          \n",
       "79998                                                1.0          \n",
       "79999                                                NaN          \n",
       "\n",
       "       HSOC Zones as of 2018-06-05 2 2 OWED Public Spaces 2 2  \\\n",
       "0                                  NaN                    NaN   \n",
       "1                                  NaN                    NaN   \n",
       "2                                  NaN                    NaN   \n",
       "3                                  NaN                    NaN   \n",
       "4                                  NaN                    NaN   \n",
       "...                                ...                    ...   \n",
       "79995                              NaN                    NaN   \n",
       "79996                              NaN                    NaN   \n",
       "79997                              NaN                    NaN   \n",
       "79998                              1.0                    NaN   \n",
       "79999                              NaN                    NaN   \n",
       "\n",
       "       Neighborhoods 2  Year  Month  Day  Hour  \n",
       "0                  5.0  2015     12   15    10  \n",
       "1                 15.0  2013     12    4    16  \n",
       "2                 97.0  2011      1   21    17  \n",
       "3                108.0  2006      8   25    20  \n",
       "4                109.0  2005      9   20    10  \n",
       "...                ...   ...    ...  ...   ...  \n",
       "79995             32.0  2012      5   12     0  \n",
       "79996             90.0  2012      2   20     9  \n",
       "79997            113.0  2013      3   18     0  \n",
       "79998             32.0  2004      7   24    23  \n",
       "79999             99.0  2014      4    4    17  \n",
       "\n",
       "[80000 rows x 40 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(df_balanced[[\"PdDistrict\",\"Year\",\"Month\",\"Day\",\"Hour\"]])\n",
    "\n",
    "y = df_balanced[\"Category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.factorize( ['VEHICLE THEFT', 'FRAUD'] )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>PdDistrict_BAYVIEW</th>\n",
       "      <th>PdDistrict_CENTRAL</th>\n",
       "      <th>PdDistrict_INGLESIDE</th>\n",
       "      <th>PdDistrict_MISSION</th>\n",
       "      <th>PdDistrict_NORTHERN</th>\n",
       "      <th>PdDistrict_PARK</th>\n",
       "      <th>PdDistrict_RICHMOND</th>\n",
       "      <th>PdDistrict_SOUTHERN</th>\n",
       "      <th>PdDistrict_TARAVAL</th>\n",
       "      <th>PdDistrict_TENDERLOIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Year, Month, Day, Hour, PdDistrict_BAYVIEW, PdDistrict_CENTRAL, PdDistrict_INGLESIDE, PdDistrict_MISSION, PdDistrict_NORTHERN, PdDistrict_PARK, PdDistrict_RICHMOND, PdDistrict_SOUTHERN, PdDistrict_TARAVAL, PdDistrict_TENDERLOIN]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(X, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.37 degrees.\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "error  = abs(test_labels-predictions.round()).sum()\n",
    "(len(test_labels)-error)/len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6802"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "error  = abs(test_labels-predictions.round()).sum()\n",
    "(len(test_labels)-error)/len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Beyond the Baseline with Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Part 2, you built a Decision Tree/Random Forest classifier to predict the category of a crime with the help of our friend `sklearn` using the following variables:\n",
    "\n",
    "* `Hour of the week` (`1 , 2, ..., 168 `). \n",
    "* `PD District` (`TENDERLOIN`, etc).  (**Remember**, You'll need to encode this  labels as integers in `sklearn`, you can just assign numbers to the labels with something like sklearn's `Label Encoder` or do your own custom function). \n",
    "\n",
    "That model from Part 2 will function as our baseline. Now that we have it set up, we can use it to understand how adding variables from a **weather dataset** will influence the decisions of the tree later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to get that weather data rolling. The raw data we are using can be found online [here](https://www.meteoblue.com/en/weather/archive/export/san-francisco_united-states-of-america_5391959) or [you can get a convenient version from the files folder our class repository by clicking here](https://raw.githubusercontent.com/suneman/socialdata2021/master/files/weather_data.csv). \n",
    "\n",
    "> *Exercise*\n",
    "> \n",
    "> * Load the weather dataset. If you have your training data and test data on separate `DataFrames` then merging them with the weather information should be simple \n",
    ">   * **Hint**: you can use the join method from pandas. To do so, you will need to round the time to the hour because weather data is recorded hourly. Also it's fine to drop missing values. Here's a [stackoverflow post](https://stackoverflow.com/questions/36292959/pandas-merge-data-frames-on-datetime-index) which may help you. \n",
    ">  * *Note*: you'll need to do some encoding on the weather data as before if you want to use the weather column. Also, check if all of the entries of the new training data have indeed a weather part to them. \n",
    "> * Now that you have the data properly merged, you can **fit a new random forest on the data and compare the results**. How does the weather data influence the prediction performances? (Use the evaluation function you built above.) Is there as impact in the accuracy of predictions? Is weather data relevant for the predictions?\n",
    "> * *Optional*: Try experimenting with using only certain variables of the weather data. Can you improve the performance of classification by using fewer features/variables?\n",
    "\n",
    "\n",
    "**Note**: It's not 100% given that adding weather will improve your predictive performance. It can go either way depending on the details of your implementation. The important thing is not performance, but that you implement your code in the right way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>weather</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-01 23:00:00+07:00</td>\n",
       "      <td>16.330000</td>\n",
       "      <td>88.0</td>\n",
       "      <td>light rain</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-02 00:00:00+07:00</td>\n",
       "      <td>16.324993</td>\n",
       "      <td>87.0</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>2.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>1009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-02 01:00:00+07:00</td>\n",
       "      <td>16.310618</td>\n",
       "      <td>86.0</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>2.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>1009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-02 02:00:00+07:00</td>\n",
       "      <td>16.296243</td>\n",
       "      <td>85.0</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>2.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>1009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-02 03:00:00+07:00</td>\n",
       "      <td>16.281869</td>\n",
       "      <td>84.0</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1009.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date  temperature  humidity       weather  wind_speed  \\\n",
       "0 2012-10-01 23:00:00+07:00    16.330000      88.0    light rain         2.0   \n",
       "1 2012-10-02 00:00:00+07:00    16.324993      87.0  sky is clear         2.0   \n",
       "2 2012-10-02 01:00:00+07:00    16.310618      86.0  sky is clear         2.0   \n",
       "3 2012-10-02 02:00:00+07:00    16.296243      85.0  sky is clear         2.0   \n",
       "4 2012-10-02 03:00:00+07:00    16.281869      84.0  sky is clear         2.0   \n",
       "\n",
       "   wind_direction  pressure  \n",
       "0           150.0    1009.0  \n",
       "1           147.0    1009.0  \n",
       "2           141.0    1009.0  \n",
       "3           135.0    1009.0  \n",
       "4           129.0    1009.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_weather = df = pd.read_csv(r\"C:\\Users\\andri\\Documents\\Andri Geir\\DTU\\Social Data\\weather_data.csv\")\n",
    "weather = pd.read_csv(\"weather_data.csv\", parse_dates=[\"date\"],\n",
    "                date_parser=lambda x: pd.to_datetime(x).tz_convert(None).tz_localize(\"Etc/GMT+3\").tz_convert(\"Etc/GMT-7\")) \n",
    "# parse_dates specifies what columns contain dates (instead of a string column -> it becomes a date_time column)\n",
    "# data_parser -> we specify our custom date_parser (Pandas has default data_parser, usually we do not need to specify it)\n",
    "# in our data_parser we use \"lambda\" function - it means that we want to apply something to each value in the column\n",
    "# pd.to_datetime(x) - converts each value to date_time obect. By default pd.to_datetime assigns GMT0 timezone, \n",
    "# which is wrong, thus, we specification of timezone with tz_convert(None)\n",
    "# now we want to specify the correct timezone -> we use tz_localize(\"..\")\n",
    "# after we can convert dates to the actual SanFrancisco timezone with tz_convert(\"..\")\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\andri\\Documents\\Andri Geir\\DTU\\Social Data\\Police_Department_Incident_Reports__Historical_2003_to_May_2018.csv\", usecols=[\"Category\", \"Date\", \"Time\", \"PdDistrict\"]) ## specify any columns you need\n",
    "print(\"df\")\n",
    "df = df[df[\"Category\"].isin(['VEHICLE THEFT', 'FRAUD'])] # filter out the dataframe, you can plug any list of crimes\n",
    "df[\"datetime\"] = df.apply(lambda x: pd.to_datetime(x.Date + \" \" + x.Time).round(\"H\").tz_localize(\"ETC/GMT-7\"), axis = 1)  \n",
    "df['Year'] = pd.DatetimeIndex(df['Date']).year\n",
    "df['Month'] = pd.DatetimeIndex(df['Date']).month\n",
    "df['Day'] = pd.DatetimeIndex(df['Date']).day\n",
    "df['Hour'] = [int(time[0:2]) for time in (df['Time'])]\n",
    "# Here we do a bit more complicated thing\n",
    "# .apply allows us to use function for each row of a dataframe (read documentation for more info)\n",
    "# so we take a row (which is x) and take cell of Date and Time -> and concatenate them to one big string\n",
    "# that can be then converted to datetime. We would also want to remove any seconds and minutes (round to hours)\n",
    "# then we specify that dates are in GMT-7\n",
    "# the result is going to be stored in new \"datetime\" column\n",
    "\n",
    "#it might take some time\n",
    "\n",
    "# now you  can merge two datasets\n",
    "# df_balanced[\"datetime\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = pd.merge(df,weather,how=\"left\",left_on =\"datetime\",right_on =\"date\")\n",
    "df_weather = df_weather.dropna(subset=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14301"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_weather[df_weather[\"Category\"]==(\"VEHICLE THEFT\")])\n",
    "len(df_weather[df_weather[\"Category\"]==(\"FRAUD\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14301\n",
      "14301\n",
      "28602\n"
     ]
    }
   ],
   "source": [
    "df_filtered1 = df_weather[df_weather[\"Category\"]==(\"VEHICLE THEFT\")].sample(14301)\n",
    "df_filtered2 = df_weather[df_weather[\"Category\"]==(\"FRAUD\")].sample(14301)\n",
    "print(len(df_filtered1))\n",
    "print(len(df_filtered2))\n",
    "df_balanced = pd.concat([df_filtered1,df_filtered2]).sample(frac=1).reset_index()\n",
    "print(len(df_balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'Category', 'Date', 'Time', 'PdDistrict', 'datetime', 'Year',\n",
       "       'Month', 'Day', 'Hour', 'date', 'temperature', 'humidity', 'weather',\n",
       "       'wind_speed', 'wind_direction', 'pressure'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(df_balanced[['PdDistrict', 'Year',\n",
    "       'Month', 'Day', 'Hour', 'temperature', 'humidity', 'weather',\n",
    "       'wind_speed', 'wind_direction', 'pressure']])\n",
    "\n",
    "y = df_balanced[\"Category\"]\n",
    "y = y.factorize( ['VEHICLE THEFT', 'FRAUD'] )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(X, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.4 degrees.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6786463431687876"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)\n",
    "# Print out the mean absolute error (mae)\n",
    "#print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "error  = abs(test_labels-predictions.round()).sum()\n",
    "(len(test_labels)-error)/len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Video Lectures and Reading\n",
    "\n",
    "Next week we'll be playing around with *explanatory data visualization*. Roughly speaking this means using data visualization to communicate your results to others. Thus, there are new things to think about. We'll start thinking about that already this week.\n",
    "\n",
    "We start with a video from from yours truly and then read a bit from a scientific article about types of explanatory dataviz. (*The video is from an old version of the class that used D3, so just ignore those parts. I'll make a new one ASAP*).\n",
    "\n",
    "[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/yHKYMGwefso/0.jpg)](https://www.youtube.com/watch?v=yHKYMGwefso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sune talks about designing visualizations.\n",
    "# from IPython.display import YouTubeVideo\n",
    "# YouTubeVideo(\"yHKYMGwefso\",width=600, height=338)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Exercises*: Explanatory data visualization\n",
    "> * What are the three key elements to keep in mind when you design an explanatory visualization?\n",
    "> * In the video I talk about (1) *overview first*,  (2) *zoom and filter*,  (3) *details on demand*. \n",
    ">   - Go online and find a visualization that follows these principles (don't use one from the video). \n",
    ">   - Explain how it does achieves (1)-(3). It might be useful to use screenshots to illustrate your explanation.\n",
    "> * Explain in your own words: How is explanatory data analysis different from exploratory data analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Reading*: [Narrative Visualization: Telling Stories with Data](http://vis.stanford.edu/files/2010-Narrative-InfoVis.pdf) by Edward Segel and Jeffrey Heer. We'll read section 1-3 today. (And the rest next time).\n",
    "\n",
    "When you get to section 3 it's fun to open up the examples mentioned by the authors in a browser and explore them as you read the text. \n",
    "\n",
    "> *Exercise*: Answer a couple of questions about the paper.\n",
    "> \n",
    "> * What is the *Oxford English Dictionary's* defintion of a narrative?\n",
    "> * What is your favorite visualization among the examples in section 3? Explain why in a few words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
